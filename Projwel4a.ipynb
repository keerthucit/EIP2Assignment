{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projwel4a.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keerthucit/EIP2Assignment/blob/master/Projwel4a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWJuISveAwd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhK70kf1BLrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFj-kAzkBRER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64 # or 128\n",
        "num_classes = 10\n",
        "epochs = 100 # increase to 250\n",
        "depth = 100 # total num layers - 40 for\tDN, 100 for DN BC\n",
        "k = 12 # growth rate\n",
        "compression = 0.5 # reduction\n",
        "dropout_rate = None # None for augmented  # 0.2 for non augmented\n",
        "\n",
        "learning_rate = 0.1 # initial\n",
        "weight_decay = 1e-4 # DCNNN paper\n",
        "momentum = 0.9 # Nesterov\n",
        "\n",
        "num_blocks = 3 # number of dense blocks in the network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teJFh_-NBVYI",
        "colab_type": "code",
        "outputId": "c788b38f-8f1e-43c2-c68e-8637794bc7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# convert to float\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize - TODO check channel mean and std normalization later\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "# save for later use in visualization\n",
        "y_train_orig = y_train\n",
        "y_test_orig = y_test\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzOs8Ca_BaZC",
        "colab_type": "code",
        "outputId": "c63d14f6-cb29-407c-c196-6bbdef032423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Normalization - channelwise 0 mean and 1 std\n",
        "\n",
        "train_gen = ImageDataGenerator( featurewise_center=True,\n",
        "                            featurewise_std_normalization=True,\n",
        "                            #rescale=1./255,\n",
        "                            width_shift_range=2./32,\n",
        "                            height_shift_range=2./32,\n",
        "                            horizontal_flip=True)\n",
        "\n",
        "train_gen.fit(x_train, seed=0)\n",
        "print (train_gen.mean)\n",
        "print (train_gen.std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[125.3069  122.95015 113.866  ]]]\n",
            "[[[62.993256 62.08861  66.705   ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssJx6J7HBAP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = train_gen.flow(x_train, y_train, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCjz0KUOBvQk",
        "colab_type": "code",
        "outputId": "355cd137-52fc-4498-f571-4bf1981f130f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(x_train[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 59.  43.  50. ... 158. 152. 148.]\n",
            " [ 16.   0.  18. ... 123. 119. 122.]\n",
            " [ 25.  16.  49. ... 118. 120. 109.]\n",
            " ...\n",
            " [208. 201. 198. ... 160.  56.  53.]\n",
            " [180. 173. 186. ... 184.  97.  83.]\n",
            " [177. 168. 179. ... 216. 151. 123.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRWzRhtRBio4",
        "colab_type": "code",
        "outputId": "fa623506-2f51-4a39-8eac-1e58ae362831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "x,y = train_datagen.next()\n",
        "print(x[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.92228484 -0.99321806 -0.9427898  ... -0.6203346  -0.65205014\n",
            "  -0.66783726]\n",
            " [-0.786311   -0.8256106  -0.7782492  ... -0.63386333 -0.65530664\n",
            "  -0.6950303 ]\n",
            " [-0.43443322 -0.4506387  -0.4517148  ... -0.62732035 -0.6605105\n",
            "  -0.7388816 ]\n",
            " ...\n",
            " [-0.28876945 -0.04232284  0.42621127 ... -1.002245   -0.5826227\n",
            "  -0.30122414]\n",
            " [ 0.10015173  0.45103657  0.7858372  ... -0.95673853 -0.41297936\n",
            "  -0.26869112]\n",
            " [ 0.38309643  0.6771028   0.86378235 ... -0.90276605 -0.33189324\n",
            "  -0.2747421 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAIGWXG7nkAp",
        "colab_type": "code",
        "outputId": "bceb4fff-2552-4834-cd69-19e6c3293e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# normalize the test set with train set params\n",
        "\n",
        "test_gen = ImageDataGenerator(featurewise_center=True,\n",
        "                            featurewise_std_normalization=True)\n",
        "\n",
        "test_gen.fit(x_train, seed=0)\n",
        "print(test_gen.mean)\n",
        "print(test_gen.std)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[125.3069  122.95015 113.866  ]]]\n",
            "[[[62.993256 62.08861  66.705   ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxpKaA6eAZnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-io7_HtMChbo",
        "colab": {}
      },
      "source": [
        "test_datagen = test_gen.flow(x_test, y_test, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9bcc48f3-7257-40a7-b239-13045eae0cb7",
        "id": "Ni1bVpXAChbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(x_test[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[158. 159. 165. ... 137. 126. 116.]\n",
            " [152. 151. 159. ... 136. 125. 119.]\n",
            " [151. 151. 158. ... 139. 130. 120.]\n",
            " ...\n",
            " [ 68.  42.  31. ...  38.  13.  40.]\n",
            " [ 61.  49.  35. ...  26.  29.  20.]\n",
            " [ 54.  56.  45. ...  24.  34.  21.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac0bcff0-0be4-4af5-bef8-9cf138cb0cde",
        "id": "PP1FlQw3Chb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "x,y = test_datagen.next()\n",
        "print(x[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.0524961  -0.10012024 -0.11599496 ... -0.06837081 -0.08424553\n",
            "  -0.11599496]\n",
            " [-0.10012024 -0.14774439 -0.1636191  ... -0.13186967 -0.13186967\n",
            "  -0.14774439]\n",
            " [-0.11599496 -0.1636191  -0.1636191  ... -0.1636191  -0.17949381\n",
            "  -0.21124326]\n",
            " ...\n",
            " [ 0.9793604   1.3286041   1.5825996  ...  1.2333559   1.2492305\n",
            "   1.28098   ]\n",
            " [ 1.1063582   1.4873513   1.6460985  ...  1.28098     1.2651052\n",
            "   1.2651052 ]\n",
            " [ 1.2174811   1.5667249   1.6778479  ...  1.3603536   1.2968547\n",
            "   1.2651052 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XNWipyuo2hT",
        "colab_type": "code",
        "outputId": "15fbf1c3-4d9e-4221-97c8-b73488e4c360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "mn  = np.mean(x_train, (0,1,2))\n",
        "print (mn)\n",
        "sd = np.std(x_train, (0,1,2))\n",
        "print (sd)\n",
        "sd = np.std(x_train)\n",
        "print (sd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[125.3069  122.95015 113.866  ]\n",
            "[62.99325  62.088604 66.70501 ]\n",
            "64.150024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3kQqT_5uHNi",
        "colab_type": "code",
        "outputId": "0ce81c23-8ba2-4798-d6af-e12472a54e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print (np.mean(x_test, (0,1,2)))\n",
        "print (np.std(x_test, (0,1,2)))\n",
        "print (np.std(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[126.02428 123.70843 114.85442]\n",
            "[62.896416 61.937508 66.70607 ]\n",
            "64.06093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erEY1j6etuUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize test data with standardize function of generator\n",
        "\n",
        "#x_test_orig = x_test.copy()\n",
        "#for i in range(len(x_test)):\n",
        "#  x_test[i]=test_gen.standardize(x_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7-OrduuXxr",
        "colab_type": "code",
        "outputId": "87747930-b286-4599-b1fa-74f6d618cb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#print (np.mean(x_test, (0,1,2)))\n",
        "#print (np.std(x_test, (0,1,2)))\n",
        "#print (np.std(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.9813678 -1.9724256 -1.7002549]\n",
            "[0.00391554 0.00391203 0.00392164]\n",
            "0.13051839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YGlPW-Zeudo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## normalize with sklearn scaler\n",
        "#from sklearn import preprocessing\n",
        "\n",
        "#scaler = preprocessing.StandardScaler().fit(x_train)\n",
        "#x_test_norm = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs7ZRf_CBuIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_layers, num_filter, growth_rate, dropout_rate = None):\n",
        "    global compression\n",
        "    global init_mrsa\n",
        "    global weight_decay\n",
        "    temp = input\n",
        "    for _ in range(num_layers):\n",
        "        BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2),\n",
        "                                       beta_regularizer=l2(weight_decay/2))(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        # 1x1 conv - bottleneck layer\n",
        "        Conv2D_1_1 = Conv2D(int(4*growth_rate),\n",
        "            (1,1),\n",
        "            use_bias=False,\n",
        "            padding='same',\n",
        "            kernel_initializer=init_mrsa,\n",
        "            kernel_regularizer=l2(weight_decay/2))(relu)\n",
        "        # 3x3 conv\n",
        "        Conv2D_3_3 = Conv2D(int(growth_rate),\n",
        "            (3,3), \n",
        "            use_bias=False, \n",
        "            padding='same',\n",
        "            kernel_initializer=init_mrsa,\n",
        "            kernel_regularizer=l2(weight_decay/2))(Conv2D_1_1)\n",
        "        if dropout_rate is not None:\n",
        "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        # concat outputs\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        num_filter += growth_rate\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp, num_filter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JqYVWITBxut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter, dropout_rate = None):\n",
        "    global compression\n",
        "    global init_mrsa\n",
        "    global weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2), \n",
        "                                beta_regularizer=l2(weight_decay/2))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), \n",
        "        kernel_initializer=init_mrsa,\n",
        "        use_bias=False, \n",
        "        padding='same',\n",
        "        kernel_regularizer=l2(weight_decay/2))(relu)\n",
        "    if dropout_rate is not None:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2), strides=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg, int(num_filter*compression)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frbFekNjB2GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input, size):\n",
        "    global compression\n",
        "    global weight_decay\n",
        "    BatchNorm = BatchNormalization(gamma_regularizer=l2(weight_decay/2), \n",
        "                                beta_regularizer=l2(weight_decay/2))(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    # try global lavg pooling\n",
        "    AvgPooling = AveragePooling2D(pool_size=(size,size))(relu)\n",
        "    # try 2x2 with 2x2 stride - gives 4x4x27\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2), strides=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dII0OWFNB5e_",
        "colab_type": "code",
        "outputId": "08beeb87-d18a-4357-e6bd-f205eb338744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# num layers in each block\n",
        "num_layers = int((depth - 4)/num_blocks) \n",
        "\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "init_mrsa = VarianceScaling(2.0) # mode = FAN_IN, distribution=normal, to get MRSA init\n",
        "# https://www.tensorflow.org/api_docs/python/tf/contrib/layers/variance_scaling_initializer\n",
        "# https://medium.com/intuitionmachine/notes-on-the-implementation-densenet-in-tensorflow-beeda9dd1504\n",
        "\n",
        "# initial number of filters - output of 1st layer is 2 * growth rate\n",
        "num_filter = k * 2 \n",
        "\n",
        "output = Conv2D(num_filter,  \n",
        "                (3,3), \n",
        "                kernel_initializer=init_mrsa,\n",
        "                use_bias=False,\n",
        "                padding='same',\n",
        "                kernel_regularizer=l2(weight_decay/2))(input) # https://bbabenko.github.io/weight-decay/\n",
        "#32x32, 24\n",
        "\n",
        "print (f'num_layers {num_layers}')\n",
        "for block in range(num_blocks): \n",
        "    # num_layers/2 due to bottleneck net - 1 1x1 and 1 3x3 in each step\n",
        "    print (f'DN: block {block} DB : in num_filter {num_filter}')\n",
        "    output, num_filter = add_denseblock(output, int(num_layers/2), num_filter, k, dropout_rate)\n",
        "    print (f'DN: block {block} DB : out num_filter {num_filter}')\n",
        "#32x32, 24+12=36, 16x16x18+12=30, 8x8x15+12=27\n",
        "    if (block != (num_blocks-1)):\n",
        "        print (f'DN: block {block} TR : in num_filter {num_filter}')\n",
        "        output, num_filter = add_transition(output, num_filter, dropout_rate)\n",
        "        print (f'DN: block {block} TR : out num_filter {num_filter}')\n",
        "#32x32, 16x16x36/2=18, 8x8x30/2=15, \n",
        "\n",
        "# 8x8x27\n",
        "output = output_layer(output, 8)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_layers 32\n",
            "DN: block 0 DB : in num_filter 24\n",
            "DN: block 0 DB : out num_filter 216\n",
            "DN: block 0 TR : in num_filter 216\n",
            "DN: block 0 TR : out num_filter 108\n",
            "DN: block 1 DB : in num_filter 108\n",
            "DN: block 1 DB : out num_filter 300\n",
            "DN: block 1 TR : in num_filter 300\n",
            "DN: block 1 TR : out num_filter 150\n",
            "DN: block 2 DB : in num_filter 150\n",
            "DN: block 2 DB : out num_filter 342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMlqOebVCAe-",
        "colab_type": "code",
        "outputId": "0ad32ff5-804c-4694-d28c-92f7f38bf75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9622
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 36)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 60)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 72)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 84)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 96)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 108)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 120)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 48)   5760        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 132)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 48)   6336        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 144)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 48)   6912        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 156)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 48)   7488        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 168)  0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 168)  672         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 168)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 48)   8064        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 180)  0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 180)  720         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 180)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 48)   8640        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 192)  0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 192)  768         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 192)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 48)   9216        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 204)  0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 204)  816         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 204)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 48)   9792        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 12)   5184        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 32, 32, 216)  0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 216)  864         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 216)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 108)  23328       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 108)  0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 108)  432         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 108)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 48)   5184        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 120)  0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 120)  480         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 120)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 48)   5760        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 132)  0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 132)  528         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 132)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 48)   6336        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 144)  0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 144)  576         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 144)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 16, 16, 48)   6912        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 156)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 156)  624         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 156)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 16, 16, 48)   7488        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 168)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 168)  672         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 168)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 48)   8064        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 180)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 180)  720         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 180)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 48)   8640        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 192)  0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 192)  768         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 192)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 48)   9216        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 204)  0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 204)  816         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 204)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 16, 16, 48)   9792        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 216)  0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 216)  864         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 216)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 16, 16, 48)   10368       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 228)  0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 228)  912         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 228)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 16, 16, 48)   10944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 240)  0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 240)  960         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 240)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 16, 16, 48)   11520       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 252)  0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 252)  1008        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 252)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 16, 16, 48)   12096       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 264)  0           concatenate_28[0][0]             \n",
            "                                                                 conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 264)  1056        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 264)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 16, 16, 48)   12672       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 276)  0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 276)  1104        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 276)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 48)   13248       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 16, 16, 288)  0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 288)  1152        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 288)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 48)   13824       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 12)   5184        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 16, 16, 300)  0           concatenate_31[0][0]             \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 300)  1200        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 300)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 150)  45000       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 150)    0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 150)    600         average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 150)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 8, 8, 48)     7200        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 162)    0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 162)    648         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 162)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 8, 8, 48)     7776        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 174)    0           concatenate_33[0][0]             \n",
            "                                                                 conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 174)    696         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 174)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 8, 8, 48)     8352        activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 186)    0           concatenate_34[0][0]             \n",
            "                                                                 conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 186)    744         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 186)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 8, 8, 48)     8928        activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 198)    0           concatenate_35[0][0]             \n",
            "                                                                 conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 198)    792         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 198)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 48)     9504        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 210)    0           concatenate_36[0][0]             \n",
            "                                                                 conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 210)    840         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 210)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 48)     10080       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 222)    0           concatenate_37[0][0]             \n",
            "                                                                 conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 222)    888         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 222)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 48)     10656       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 234)    0           concatenate_38[0][0]             \n",
            "                                                                 conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 234)    936         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 234)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 48)     11232       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 246)    0           concatenate_39[0][0]             \n",
            "                                                                 conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 246)    984         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 246)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 48)     11808       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 258)    0           concatenate_40[0][0]             \n",
            "                                                                 conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 258)    1032        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 258)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 48)     12384       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 270)    0           concatenate_41[0][0]             \n",
            "                                                                 conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 270)    1080        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 270)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 48)     12960       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 282)    0           concatenate_42[0][0]             \n",
            "                                                                 conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 282)    1128        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 282)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 48)     13536       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 294)    0           concatenate_43[0][0]             \n",
            "                                                                 conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 294)    1176        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 294)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 48)     14112       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 306)    0           concatenate_44[0][0]             \n",
            "                                                                 conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 306)    1224        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 306)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 48)     14688       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 8, 8, 318)    0           concatenate_45[0][0]             \n",
            "                                                                 conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 318)    1272        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 8, 8, 318)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 48)     15264       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 8, 8, 330)    0           concatenate_46[0][0]             \n",
            "                                                                 conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 330)    1320        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 8, 8, 330)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 48)     15840       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 12)     5184        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 8, 8, 342)    0           concatenate_47[0][0]             \n",
            "                                                                 conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 342)    1368        concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 8, 8, 342)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 342)    0           activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 342)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           3430        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 783,934\n",
            "Trainable params: 764,554\n",
            "Non-trainable params: 19,380\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P094KuFNCGdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "# LR decay = 0.1/250/4 = 1.0e-4\n",
        "sgd = SGD(lr=learning_rate,momentum=momentum, decay=1.0e-4, nesterov=True)\n",
        "\n",
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=Adam(),\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP_Sb-OHCScm",
        "colab_type": "code",
        "outputId": "2abe0755-9b5e-48c0-e8bf-6181a6554ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "#filepath=\"/content/gdrive/My Drive/EIP2/Session4/1/DCNN_v2_best.h5\"\n",
        "filepath=\"/content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-{epoch:02d}-{val_acc:.2f}.h5\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hscp-Dp6pKUI",
        "colab_type": "code",
        "outputId": "6fec8710-c68b-44a5-edf7-d6fe08194262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('/content/gdrive/My Drive/EIP2/Session4/2/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/gdrive/My\\ Drive/EIP2/Session4/1/foo.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KxKLKs6Sqwi",
        "colab_type": "code",
        "outputId": "68b116f7-3546-4396-af1c-583640c95c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!rm -rf clr_callback.py*\n",
        "!wget https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
        "from clr_callback import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-03 18:23:55--  https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py [following]\n",
            "--2018-11-03 18:23:56--  https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5326 (5.2K) [text/plain]\n",
            "Saving to: ‘clr_callback.py’\n",
            "\n",
            "clr_callback.py     100%[===================>]   5.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-03 18:23:57 (67.8 MB/s) - ‘clr_callback.py’ saved [5326/5326]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JmMHuwCeSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#filepath=\"DNST_model-{epoch:02d}-{val_acc:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CUMbxT8YpJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add CLR callback\n",
        "clr_triangular = CyclicLR(mode='triangular2', base_lr=0.0003, max_lr=0.1, step_size=2500)\n",
        "callbacks_list.append(clr_triangular)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5etWEomx2Ip-",
        "colab_type": "code",
        "outputId": "cf551740-de50-40dd-b1c9-26d1c8ae8007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1788
        }
      },
      "source": [
        "model.fit_generator(train_gen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch = x_train.shape[0]/(batch_size/2),\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_gen.flow(x_test, y_test, batch_size=50),\n",
        "                    callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/100\n",
            "1563/1562 [==============================] - 626s 401ms/step - loss: 1.9488 - acc: 0.5552 - val_loss: 2.6957 - val_acc: 0.5299\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.52990, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-01-0.53.h5\n",
            "Epoch 2/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 1.3390 - acc: 0.7574 - val_loss: 1.2676 - val_acc: 0.7739\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.52990 to 0.77390, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-02-0.77.h5\n",
            "Epoch 3/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 1.0150 - acc: 0.8455 - val_loss: 0.9674 - val_acc: 0.8591\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.77390 to 0.85910, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-03-0.86.h5\n",
            "Epoch 4/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.8744 - acc: 0.8877 - val_loss: 0.9980 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.85910\n",
            "Epoch 5/100\n",
            "1563/1562 [==============================] - 613s 392ms/step - loss: 0.8844 - acc: 0.8752 - val_loss: 0.9983 - val_acc: 0.8314\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.85910\n",
            "Epoch 6/100\n",
            "1563/1562 [==============================] - 613s 393ms/step - loss: 0.8009 - acc: 0.8966 - val_loss: 0.8502 - val_acc: 0.8770\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.85910 to 0.87700, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-06-0.88.h5\n",
            "Epoch 7/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.7068 - acc: 0.9259 - val_loss: 0.8341 - val_acc: 0.8851\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.87700 to 0.88510, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-07-0.89.h5\n",
            "Epoch 8/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.7114 - acc: 0.9205 - val_loss: 0.8600 - val_acc: 0.8738\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.88510\n",
            "Epoch 9/100\n",
            "1563/1562 [==============================] - 615s 394ms/step - loss: 0.6890 - acc: 0.9250 - val_loss: 0.7943 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.88510 to 0.89400, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-09-0.89.h5\n",
            "Epoch 10/100\n",
            "1563/1562 [==============================] - 615s 393ms/step - loss: 0.6339 - acc: 0.9430 - val_loss: 0.7748 - val_acc: 0.8994\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.89400 to 0.89940, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-10-0.90.h5\n",
            "Epoch 11/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.6296 - acc: 0.9433 - val_loss: 0.8533 - val_acc: 0.8783\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.89940\n",
            "Epoch 12/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.6247 - acc: 0.9430 - val_loss: 0.7769 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.89940\n",
            "Epoch 13/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.5960 - acc: 0.9528 - val_loss: 0.7655 - val_acc: 0.9008\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.89940 to 0.90080, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-13-0.90.h5\n",
            "Epoch 14/100\n",
            "1563/1562 [==============================] - 615s 394ms/step - loss: 0.5897 - acc: 0.9542 - val_loss: 0.7750 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.90080\n",
            "Epoch 15/100\n",
            "1563/1562 [==============================] - 618s 396ms/step - loss: 0.5889 - acc: 0.9539 - val_loss: 0.7763 - val_acc: 0.8976\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.90080\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 617s 395ms/step - loss: 0.5741 - acc: 0.9594 - val_loss: 0.7639 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.90080 to 0.90240, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-16-0.90.h5\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.5696 - acc: 0.9598 - val_loss: 0.7702 - val_acc: 0.9001\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.90240\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 616s 394ms/step - loss: 0.5700 - acc: 0.9600 - val_loss: 0.7730 - val_acc: 0.8987\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.90240\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 615s 394ms/step - loss: 0.5653 - acc: 0.9608 - val_loss: 0.7633 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.90240\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 615s 393ms/step - loss: 0.5621 - acc: 0.9622 - val_loss: 0.7650 - val_acc: 0.9026\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.90240 to 0.90260, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-20-0.90.h5\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.5613 - acc: 0.9622 - val_loss: 0.7645 - val_acc: 0.9019\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.90260\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.5582 - acc: 0.9636 - val_loss: 0.7655 - val_acc: 0.9015\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.90260\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 615s 394ms/step - loss: 0.5564 - acc: 0.9648 - val_loss: 0.7644 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.90260\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 614s 393ms/step - loss: 0.5580 - acc: 0.9630 - val_loss: 0.7665 - val_acc: 0.9014\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.90260\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 615s 393ms/step - loss: 0.5565 - acc: 0.9635 - val_loss: 0.7639 - val_acc: 0.9020\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.90260\n",
            "Epoch 26/100\n",
            " 738/1562 [=============>................] - ETA: 5:11 - loss: 0.5552 - acc: 0.9628"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ84mGCYW2Yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fb720131-4da2-4bd6-c13e-2b95e59f4cb2",
        "id": "meq0QGecXJZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "#filepath=\"/content/gdrive/My Drive/EIP2/Session4/1/DCNN_v2_best.h5\"\n",
        "filepath=\"/content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-{epoch:02d}-{val_acc:.2f}.h5\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8085f89e-c33a-4a9f-cb89-9b8d0d7c4b72",
        "id": "L_EJyez8XJZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('/content/gdrive/My Drive/EIP2/Session4/2/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/gdrive/My\\ Drive/EIP2/Session4/1/foo.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RoVkiyrWbbv",
        "colab_type": "code",
        "outputId": "8eff9ddc-b82e-4cc0-b199-bbd0c8a6b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_model = \"DCNN_v3-20-0.90.h5\"\n",
        "model_path = \"/content/gdrive/My Drive/EIP2/Session4/2/\"+best_model\n",
        "print (model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-20-0.90.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsEL92tVwVgi",
        "colab_type": "code",
        "outputId": "94f8d018-f370-43c7-e9ce-8f1ca1b1eccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwxZli7PWaaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuEod6dYC0cg",
        "colab_type": "code",
        "outputId": "f4850b35-c041-4004-946b-26eb66ba1073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "#score = model.evaluate(x_test, y_test, verbose=1)\n",
        "score = model.evaluate_generator(test_gen.flow(x_test, y_test, batch_size=1), verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 386s 39ms/step\n",
            "Test loss: 0.7599838314890861\n",
            "Test accuracy: 0.9029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FitG4MqoXJZO",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "# LR decay = 0.1/250/4 = 1.0e-4\n",
        "sgd = SGD(lr=learning_rate,momentum=momentum, decay=1.0e-4, nesterov=True)\n",
        "\n",
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=Adam(),\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f8b76f6-feb4-4b02-a684-bb17c5d1ded5",
        "id": "EiNjzk5qXJZb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!rm -rf clr_callback.py*\n",
        "!wget https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
        "from clr_callback import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-03 02:36:14--  https://github.com/bckenstler/CLR/raw/master/clr_callback.py\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py [following]\n",
            "--2018-11-03 02:36:14--  https://raw.githubusercontent.com/bckenstler/CLR/master/clr_callback.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5326 (5.2K) [text/plain]\n",
            "Saving to: ‘clr_callback.py’\n",
            "\n",
            "\rclr_callback.py       0%[                    ]       0  --.-KB/s               \rclr_callback.py     100%[===================>]   5.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-11-03 02:36:14 (62.4 MB/s) - ‘clr_callback.py’ saved [5326/5326]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DMqMlD8NXJZ0",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#filepath=\"DNST_model-{epoch:02d}-{val_acc:.2f}.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1K5N23XcXJZ4",
        "colab": {}
      },
      "source": [
        "# add CLR callback\n",
        "clr_triangular = CyclicLR(mode='triangular2', base_lr=0.0003, max_lr=0.1, step_size=2500)\n",
        "callbacks_list.append(clr_triangular)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ad78a2b3-2b40-409b-93fa-9e0385459a17",
        "id": "GA4lmmzdXJZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit_generator(train_gen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch = x_train.shape[0]/(batch_size/2),\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_gen.flow(x_test, y_test, batch_size=50),\n",
        "                    callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1562 [==============================] - 629s 402ms/step - loss: 0.7535 - acc: 0.8911 - val_loss: 1.1682 - val_acc: 0.7648\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.76480, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-01-0.76.h5\n",
            "Epoch 2/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.8187 - acc: 0.8604 - val_loss: 0.8647 - val_acc: 0.8477\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.76480 to 0.84770, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-02-0.85.h5\n",
            "Epoch 3/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.6480 - acc: 0.9088 - val_loss: 0.6702 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.84770 to 0.89900, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-03-0.90.h5\n",
            "Epoch 4/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.5405 - acc: 0.9423 - val_loss: 0.7036 - val_acc: 0.8880\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.89900\n",
            "Epoch 5/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.5694 - acc: 0.9268 - val_loss: 0.7130 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.89900\n",
            "Epoch 6/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.5087 - acc: 0.9418 - val_loss: 0.6389 - val_acc: 0.8989\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.89900\n",
            "Epoch 7/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.4470 - acc: 0.9617 - val_loss: 0.6172 - val_acc: 0.9101\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.89900 to 0.91010, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-07-0.91.h5\n",
            "Epoch 8/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.4491 - acc: 0.9595 - val_loss: 0.6500 - val_acc: 0.8959\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.91010\n",
            "Epoch 9/100\n",
            "1563/1562 [==============================] - 618s 396ms/step - loss: 0.4335 - acc: 0.9622 - val_loss: 0.6105 - val_acc: 0.9091\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.91010\n",
            "Epoch 10/100\n",
            "1563/1562 [==============================] - 618s 396ms/step - loss: 0.4004 - acc: 0.9730 - val_loss: 0.5999 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.91010 to 0.91370, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-10-0.91.h5\n",
            "Epoch 11/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.3959 - acc: 0.9747 - val_loss: 0.6201 - val_acc: 0.9105\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.91370\n",
            "Epoch 12/100\n",
            "1563/1562 [==============================] - 618s 396ms/step - loss: 0.3956 - acc: 0.9728 - val_loss: 0.6017 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.91370\n",
            "Epoch 13/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.3787 - acc: 0.9786 - val_loss: 0.5896 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.91370 to 0.91710, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-13-0.92.h5\n",
            "Epoch 14/100\n",
            "1563/1562 [==============================] - 618s 396ms/step - loss: 0.3734 - acc: 0.9803 - val_loss: 0.5934 - val_acc: 0.9171\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.91710 to 0.91710, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-14-0.92.h5\n",
            "Epoch 15/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.3738 - acc: 0.9792 - val_loss: 0.5929 - val_acc: 0.9163\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.91710\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.3662 - acc: 0.9822 - val_loss: 0.5933 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.91710\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.3651 - acc: 0.9826 - val_loss: 0.5945 - val_acc: 0.9154\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.91710\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.3643 - acc: 0.9823 - val_loss: 0.5930 - val_acc: 0.9173\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.91710 to 0.91730, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-18-0.92.h5\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 619s 396ms/step - loss: 0.3617 - acc: 0.9830 - val_loss: 0.5944 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.91730\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 618s 395ms/step - loss: 0.3618 - acc: 0.9827 - val_loss: 0.5927 - val_acc: 0.9175\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.91730 to 0.91750, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-20-0.92.h5\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 622s 398ms/step - loss: 0.3599 - acc: 0.9837 - val_loss: 0.5924 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.91750 to 0.91810, saving model to /content/gdrive/My Drive/EIP2/Session4/2/DCNN_v3-2-21-0.92.h5\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 620s 397ms/step - loss: 0.3593 - acc: 0.9836 - val_loss: 0.5916 - val_acc: 0.9178\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.91810\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 620s 397ms/step - loss: 0.3588 - acc: 0.9838 - val_loss: 0.5939 - val_acc: 0.9177\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.91810\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 621s 397ms/step - loss: 0.3585 - acc: 0.9838 - val_loss: 0.5942 - val_acc: 0.9170\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.91810\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 620s 397ms/step - loss: 0.3569 - acc: 0.9847 - val_loss: 0.5947 - val_acc: 0.9179\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.91810\n",
            "Epoch 26/100\n",
            "1563/1562 [==============================] - 621s 397ms/step - loss: 0.3561 - acc: 0.9847 - val_loss: 0.5935 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.91810\n",
            "Epoch 27/100\n",
            "  93/1562 [>.............................] - ETA: 9:21 - loss: 0.3544 - acc: 0.9852"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpGBujebNLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}